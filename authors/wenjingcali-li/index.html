<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Author: Wenjing(Cali) Li - Visualization</title><meta name="robots" content="noindex, follow"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="alternate" type="application/atom+xml" href="https://cali-li.github.io/Data-Visualization/feed.xml"><link rel="alternate" type="application/json" href="https://cali-li.github.io/Data-Visualization/feed.json"><meta property="og:title" content="Wenjing(Cali) Li"><meta property="og:site_name" content="Visualization"><meta property="og:description" content=""><meta property="og:url" content="https://cali-li.github.io/Data-Visualization/authors/wenjingcali-li/"><meta property="og:type" content="website"><link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin><style>h1,h2,h3,h4,h5,h6,.btn,[type=button],[type=submit],button,.navbar .navbar__menu li,.navbar_mobile_sidebar .navbar__menu li,.feed__author,.post__tag,.post__share>a span,.post__nav-link>span,.footer{font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen,Ubuntu,Cantarell,"Fira Sans","Droid Sans","Helvetica Neue",Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol"}body,h1,.h1,blockquote,.search__input,.author__name,.author__info>p,.feed__item h2,.post__nav-link{font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen,Ubuntu,Cantarell,"Fira Sans","Droid Sans","Helvetica Neue",Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol"}</style><link rel="stylesheet" href="https://cali-li.github.io/Data-Visualization/assets/css/style.css?v=cc87cb8806c844f0646558fe70d5c5d1"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Organization","name":"Visualization","url":"https://cali-li.github.io/Data-Visualization/"}</script><script src="https://cali-li.github.io/Data-Visualization/assets/js/ls.parent-fit.min.js?v=f8467455ea5c88e3e51a4f212d2632bd"></script><script async src="https://cali-li.github.io/Data-Visualization/assets/js/lazysizes.min.js?v=6a69d476c93de2b78a72acb259abccea"></script></head><body><div class="site-container"><header class="top" id="js-header"><a class="logo" href="https://cali-li.github.io/Data-Visualization/">Visualization</a><nav class="navbar js-navbar"><button class="navbar__toggle js-toggle" aria-label="Menu" aria-haspopup="true" aria-expanded="false"><span class="navbar__toggle-box"><span class="navbar__toggle-inner">Menu</span></span></button><ul class="navbar__menu"><li><a href="https://cali-li.github.io/Data-Visualization/" target="_self">Home</a></li><li class="has-submenu"><a href="https://public.tableau.com/views/DEMOfordognition/Story1?:display_count&#x3D;y&amp;:origin&#x3D;viz_share_link" target="_self" aria-haspopup="true">Tableau</a><ul class="navbar__submenu level-2" aria-hidden="true"><li><a href="https://cali-li.github.io/Data-Visualization/banana-project-2.html" target="_self">Dognition</a></li></ul></li><li><a href="https://github.com/cali-li" target="_self">GitHub</a></li><li class="active"><a href="https://cali-li.github.io/Data-Visualization/authors/wenjingcali-li/" target="_self">Author</a></li></ul></nav><div class="search"><div class="search__overlay js-search-overlay"><div class="search__overlay-inner"><form action="https://cali-li.github.io/Data-Visualization/search.html" class="search__form"><input class="search__input js-search-input" type="search" name="q" placeholder="search..." autofocus="autofocus"></form><button class="search__close js-search-close" aria-label="Close">Close</button></div></div><button class="search__btn js-search-btn" aria-label="Search"><svg role="presentation" focusable="false"><use xlink:href="https://cali-li.github.io/Data-Visualization/assets/svg/svg-map.svg#search"/></svg></button></div></header><main><div class="hero"><header class="hero__content"><div class="wrapper"><h1>Wenjing(Cali) Li <sup>(5)</sup></h1><p>MS Statistics Candidate at University of Michigan</p></div></header></div><div class="feed"><article class="feed__item"><header class="wrapper"><div class="feed__meta"><time datetime="2020-01-25T18:39" class="feed__date">January 25, 2020</time></div><h2><a href="https://cali-li.github.io/Data-Visualization/recurrent-neural-network.html" class="invert">Recurrent Neural Network</a></h2></header><div class="wrapper"><h2>Introduction</h2><p>Standard network works well usually, however, it still have some problems.</p><p>Though we can include as many hidden layers as we want in the standard neural network, the input and output can only be the same length. That is not quite useful in application, since you cannot translate "I like Natural Language Processing a lot!" to "我爱自然语言处理很多！", which sounds really wierd.</p><p>The other problem is it doesn't share features learned across different positions of text. Like the sentence "Cali and Wenjing are good friends." If we got a sign that "Cali" is a name, we want the the network autometically considers "Wenjing" is another person's name.</p><p>The basic idea of RNN is showed in the graph below.</p><figure class="post__image post__image--center"><img src="https://cali-li.github.io/Data-Visualization/media/posts/6/WeChat-Image_20200125202017.jpg" sizes="(max-width: 48em) 100vw, 768px" srcset="https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/WeChat-Image_20200125202017-xs.jpg 300w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/WeChat-Image_20200125202017-sm.jpg 480w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/WeChat-Image_20200125202017-md.jpg 768w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/WeChat-Image_20200125202017-lg.jpg 1024w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/WeChat-Image_20200125202017-xl.jpg 1360w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/WeChat-Image_20200125202017-2xl.jpg 1600w" alt="RNN intuitive" width="1024" height="591"><figcaption>RNN Intuitive(many-to-many)</figcaption></figure><h3>Many-to-one Case</h3><p>However, one of the advantange of RNN is it can make the output differs from the input. Many-to-one can give us a good intuition. One application of many-to-one case is the sentiment classification, when input is a sentence, that means n words(N = n), and output is a score between 1 - 5.</p><figure class="post__image post__image--center"><img src="https://cali-li.github.io/Data-Visualization/media/posts/6/1.jpg" sizes="(max-width: 48em) 100vw, 768px" srcset="https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/1-xs.jpg 300w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/1-sm.jpg 480w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/1-md.jpg 768w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/1-lg.jpg 1024w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/1-xl.jpg 1360w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/1-2xl.jpg 1600w" alt="m-to-o" width="966" height="579"><figcaption>RNN Intuitive(many-to-one)</figcaption></figure><h3>One-to-many Case</h3><p>One-to-many case is almost the same. It usually works in the music generation. You can input a single integer, or even a NULL.</p><figure class="post__image post__image--center"><img src="https://cali-li.github.io/Data-Visualization/media/posts/6/2.jpg" sizes="(max-width: 48em) 100vw, 768px" srcset="https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/2-xs.jpg 300w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/2-sm.jpg 480w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/2-md.jpg 768w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/2-lg.jpg 1024w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/2-xl.jpg 1360w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/2-2xl.jpg 1600w" alt="" width="893" height="512"><figcaption>RNN Intuitive(one-to-many)</figcaption></figure><h3>Many-to-many Case</h3><h4>Intuition</h4><p>Many-to-many case can also be fancy. In the pragh below, we can actually divide the RNN into two parts. The first part is the encode part, where we input X and output nothing; the second part is the decode part, where, in contrast, we only output Y.</p><figure class="post__image post__image--center"><img src="https://cali-li.github.io/Data-Visualization/media/posts/6/3.jpg" sizes="(max-width: 48em) 100vw, 768px" srcset="https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/3-xs.jpg 300w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/3-sm.jpg 480w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/3-md.jpg 768w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/3-lg.jpg 1024w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/3-xl.jpg 1360w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/3-2xl.jpg 1600w" alt="" width="1230" height="514"><figcaption>RNN Intuitive(many-to-many)</figcaption></figure><h4>Application - Machine Translation</h4><p>(English)Input: x = "I like Natural Language Processing a lot!"</p><p>(Chinese)Output: y = "我非常喜欢自然语言处理！"</p><p>The result above is from Google Translate(<a href="https://translate.google.com/">https://translate.google.com/</a>)</p><h3>Conclusion</h3><p>Input X is the vector of x_i, i = 1...N. y_i is effected not only by x_2, but also by y_1...y_(i-1). RNN is quite useful in machine translation, word prediction, sentiment classification and name entity recognition.</p><hr><h2>Application: Sentence Representation</h2><h3>Word Representation</h3><p>The basic idea is to define a dictionary(or sometimes people call this vocabulary) first. The dictionary contains all the words you might be interested in. Usually we can choose the public corpus like STS and SSTB.</p><p>And then tokenize is one of the most important step. The tokenize in RNN is similar to the tokenize method in the standard network. Since the vacabulary is relatively large, usually above 50k, we need to use sparse matrix to represent it.</p><p>After that, we need to train the model over some text files and start to play around!</p><h3>Character Representation</h3><p>The intuition of the character model is similar. The only difference due to the input X. In the character model, we consider single letter as an input. The advantage of this model compared with the previous one is that it can deal with unknown words more smoothly, though it is relatively expensive to compute. With the high-performance of modern computer, the character model has become more and more popular.</p><hr><h2>Adjustification</h2><h3>Vanishing Gradients</h3><p>The basic idea of the computation of RNN is the same with standard network, using forward-propogation and back-propogation. RNN is mainly local influence, meaning that the value of Ym is mainly influenced by values Xi close to Ym. We always call this vanishing gradients. Vanishing gradients makes RNN a network not quite useful in long depending sentence. This is one of the RNN's drawbacks.</p><h3>GRU</h3><figure class="post__image post__image--center"><img src="https://cali-li.github.io/Data-Visualization/media/posts/6/Untitled-drawing.png" sizes="(max-width: 48em) 100vw, 768px" srcset="https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/Untitled-drawing-xs.png 300w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/Untitled-drawing-sm.png 480w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/Untitled-drawing-md.png 768w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/Untitled-drawing-lg.png 1024w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/Untitled-drawing-xl.png 1360w, https://cali-li.github.io/Data-Visualization/media/posts/6/responsive/Untitled-drawing-2xl.png 1600w" alt="" width="960" height="720"><figcaption>GRU Institutive</figcaption></figure><p>The basic thought of GRU is using update function Γ as a signal. For example, in sentence "The girl with superpower ...(omit relatively long matrial) is working". In standard RNN, since the sentence is long, the influence of "girl" to the word "has" is quite small and we can unsider it 0 if the sentence is long enough. However, in GRU model, the function Γ(u) equals to 0 until the model meet the word "girl", the function Γ(u) get a new value 1, that is called update the Γ to 1. Though the sentence is long, the value of Γ won't change until it meet another word "has".</p><p> The Γ function is just like a signal, using small memory to store the information of very long dependency.</p><h3>LSTM</h3><p>Similar to GRU, the main difference is LSTM has 3 gates(update gate, forget gate and output gate) while GRU has 2 gates(update gate and output gate) as shown above. LSTM is much more complicated than GRU, since it requires more computation.</p><hr><h2>Model in Python</h2><p>This notes is based on Keras.</p><pre>from keras.prepocessing.sequence import pad_sequences<br>from keras.models import Sequential<br>from keras.layers import Embedding, LSTM<br>import numpy as np<br><br>embedding_length = 5<br>max_doc = 10<br>encoded = pad_sequences(encoded_doc, truncating = "post", padding = "post", maxlen = max_doc)</pre><p>Then create the model.</p><pre>model = Sequential()<br>model.add(Embedding(vocab_size, embedding_size, input_length = max_doc))<br>model.add(LSTM(units=64))<br>model.compile("rmsprop", "mse")<br>model.summary()<br>output = model.predict(encoded_doc)<br>print(output)</pre><hr><h2>BRNN</h2><p>RNN works pretty well in general cases. However, this model is not perfect. The main problem of RNN is it cannot use future information. Like when you compute the 2nd output, you cannot take inputs later than 2nd into account. In order to getting information from the future, we can use BRNN(Bidirectional RNN).</p><p> Adding forward activation and backward activation together, BRNN uses past information and future information, making the model become more and more popular.</p><a href="https://cali-li.github.io/Data-Visualization/recurrent-neural-network.html" class="readmore feed__readmore invert">Continue reading...</a></div></article><article class="feed__item"><header class="wrapper"><div class="feed__meta"><time datetime="2020-01-21T18:30" class="feed__date">January 21, 2020</time></div><h2><a href="https://cali-li.github.io/Data-Visualization/python-basic-tutorial.html" class="invert">Python Basic Tutorial</a></h2></header><div class="wrapper"><p>This post contains some basic syntax and usage in Python. Part One Methods in list. ''' Basic methods about list ''' list.append(x) #adds x to the end of the list list.extend(L) #concatenates list L to the end of the other list list.sort() #sorts the elements&hellip;</p><a href="https://cali-li.github.io/Data-Visualization/python-basic-tutorial.html" class="readmore feed__readmore invert">Continue reading...</a></div></article><article class="feed__item"><header class="wrapper"><div class="feed__meta"><time datetime="2019-12-13T21:08" class="feed__date">December 13, 2019</time></div><h2><a href="https://cali-li.github.io/Data-Visualization/project.html" class="invert">Project</a></h2></header><div class="wrapper"><p>Group Project Report, Stats 506, F19</p><a href="https://cali-li.github.io/Data-Visualization/project.html" class="readmore feed__readmore invert">Continue reading...</a></div></article><article class="feed__item"><header class="wrapper"><div class="feed__meta"><time datetime="2019-12-07T23:47" class="feed__date">December 7, 2019</time></div><h2><a href="https://cali-li.github.io/Data-Visualization/banana-project-2.html" class="invert">banana project</a></h2></header><div class="wrapper"><p>file:///C:/Users/wenji/Downloads/viz_sum%20up/Project2_banana-project.html Introduction</p><a href="https://cali-li.github.io/Data-Visualization/banana-project-2.html" class="readmore feed__readmore invert">Continue reading...</a></div></article><article class="feed__item"><header class="wrapper"><div class="feed__meta"><time datetime="2019-12-06T11:31" class="feed__date">December 6, 2019</time></div><h2><a href="https://cali-li.github.io/Data-Visualization/what-to-know-more-about-me.html" class="invert">Want to know more about me?</a></h2></header><div class="wrapper"><p>I am currently a MS Statistics candidate at University of Michigan. I like party and data. Hope you can find some interesting thing over my website and if you have any thought please lei me know. I will be glad to explore new tech. Do&hellip;</p><a href="https://cali-li.github.io/Data-Visualization/what-to-know-more-about-me.html" class="readmore feed__readmore invert">Continue reading...</a></div></article></div></main><footer class="footer"><div class="footer__copyright">Powered by <a href="https://getpublii.com" target="_blank" rel="nofollow noopener noreferrer">Publii Static CMS</a></div><button class="footer__bttop js-footer__bttop" aria-label="Back to top"><svg><title>Back to top</title><use xlink:href="https://cali-li.github.io/Data-Visualization/assets/svg/svg-map.svg#toparrow"/></svg></button></footer></div><script>window.publiiThemeMenuConfig = {    
        mobileMenuMode: 'sidebar',
        animationSpeed: 300,
        submenuWidth: 'auto',
        doubleClickTime: 500,
        mobileMenuExpandableSubmenus: true, 
        relatedContainerForOverlayMenuSelector: '.top',
   };</script><script defer="defer" src="https://cali-li.github.io/Data-Visualization/assets/js/scripts.min.js?v=205f40927e4a45297a0b266e50ad78d5"></script><script>var lazyFeaturedImage=function lazyFeaturedImage(){var b=document.querySelectorAll(".hero__image-img");for(var a=0;a<b.length;a++){var c=b[a];c.addEventListener("lazyloaded",function(f){var d=f.target.parentNode;d.classList.add("hero__image--overlay")})}};lazyFeaturedImage();</script></body></html>